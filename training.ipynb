{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lib.model import FNO1d\n",
    "from lib.dataset import PDEDataset\n",
    "from lib.utils import relative_l2_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "DEVICE = \"mps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = (\n",
    "    PDEDataset(\"data/train_allen_cahn_fourier.npy\", device=DEVICE)\n",
    "    + PDEDataset(\"data/train_allen_cahn_gmm.npy\", device=DEVICE)\n",
    "    + PDEDataset(\"data/train_allen_cahn_piecewise.npy\", device=DEVICE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, validation_data = torch.utils.data.random_split(\n",
    "    dataset_train, [int(0.8 * len(dataset_train)), int(0.2 * len(dataset_train))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data_loader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_data_loader = DataLoader(validation_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 50\n",
    "step_size = 5\n",
    "gamma = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = 16\n",
    "width = 64\n",
    "fno = FNO1d(modes, width).to(DEVICE)  # model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(fno.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_f(output: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "    return relative_l2_error(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"training_loss\": [],\n",
    "    \"validation_loss\": [],\n",
    "    \"lr\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar = tqdm.tqdm(range(epochs))\n",
    "for epoch in progress_bar:\n",
    "    fno.train()\n",
    "    train_loss = 0.0\n",
    "    for i, (dt, input, target) in enumerate(train_data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        prediction = fno(input, dt).squeeze(-1)\n",
    "\n",
    "        loss = loss_f(prediction, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_data_loader)\n",
    "    scheduler.step()\n",
    "\n",
    "    metrics[\"training_loss\"].append(train_loss)\n",
    "    metrics[\"lr\"].append(scheduler.get_last_lr())\n",
    "\n",
    "    # Compute validation loss\n",
    "    with torch.no_grad():\n",
    "        fno.eval()\n",
    "        validation_relative_l2 = 0.0\n",
    "        for i, (dt, input, target) in enumerate(val_data_loader):\n",
    "            prediction = fno(input, dt).squeeze(-1)\n",
    "\n",
    "            loss = relative_l2_error(prediction, target)\n",
    "            validation_relative_l2 += loss.item()\n",
    "\n",
    "        validation_relative_l2 /= len(val_data_loader)\n",
    "        metrics[\"validation_loss\"].append(validation_relative_l2)\n",
    "\n",
    "    # Update progress bar\n",
    "    progress_bar.set_postfix(\n",
    "        {\"train_loss\": train_loss, \"val_loss\": validation_relative_l2}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(metrics[\"training_loss\"], label=\"Training Loss\")\n",
    "plt.plot(metrics[\"validation_loss\"], label=\"Validation Loss\")\n",
    "# plt.plot(learning_rates, label=\"Learning Rate\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.grid(True, which=\"both\", ls=\":\", linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = (\n",
    "    PDEDataset(\"data/test_allen_cahn_fourier.npy\", device=DEVICE)\n",
    "    + PDEDataset(\"data/test_allen_cahn_gmm.npy\", device=DEVICE)\n",
    "    + PDEDataset(\"data/test_allen_cahn_piecewise.npy\", device=DEVICE)\n",
    ")\n",
    "test_data_loader = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fno.eval()\n",
    "progress_bar = tqdm.tqdm(test_data_loader)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_relative_l2 = 0.0\n",
    "    for i, (dt, input, target) in enumerate(progress_bar):\n",
    "        prediction = fno(input, dt).squeeze(-1)\n",
    "\n",
    "        loss = relative_l2_error(prediction, target)\n",
    "        test_relative_l2 += loss.item()\n",
    "    test_relative_l2 /= len(test_data_loader)\n",
    "\n",
    "print(rf\"Test relative L2 error: {test_relative_l2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to disk\n",
    "torch.save(fno.state_dict(), \"models/tfno_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
